{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06fe6073-206e-4ca7-80d1-e86b43f0cd69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-21T17:48:08.315418Z",
     "iopub.status.busy": "2025-09-21T17:48:08.315145Z",
     "iopub.status.idle": "2025-09-21T17:49:28.850674Z",
     "shell.execute_reply": "2025-09-21T17:49:28.850076Z",
     "shell.execute_reply.started": "2025-09-21T17:48:08.315396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded S3 data: nurses, rules, demand, shift_def, example_roster\n",
      "Loaded XGBoost booster from /tmp/tmpwwj7py1r/xgboost-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_407/894333648.py:70: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path=tmpdir)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Episode 1 ===\n",
      "Raw model output (first 5000 chars):\n",
      " {\n",
      "  \"departments\": [\n",
      "    {\n",
      "      \"name\": \"General\",\n",
      "      \"nurses\": [\n",
      "        {\n",
      "          \"id\": \"N001\",\n",
      "          \"shifts\": [\n",
      "            {\n",
      "              \"day\": \"Mon\",\n",
      "              \"shift\": \"Full-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Tue\",\n",
      "              \"shift\": \"Full-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Wed\",\n",
      "              \"shift\": \"Full-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Thu\",\n",
      "              \"shift\": \"Full-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Fri\",\n",
      "              \"shift\": \"Full-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Sat\",\n",
      "              \"shift\": \"Full-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Sun\",\n",
      "              \"shift\": \"Full-Morning\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"id\": \"N002\",\n",
      "          \"shifts\": [\n",
      "            {\n",
      "              \"day\": \"Mon\",\n",
      "              \"shift\": \"Full-Evening\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Tue\",\n",
      "              \"shift\": \"Full-Evening\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Wed\",\n",
      "              \"shift\": \"Full-Evening\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Thu\",\n",
      "              \"shift\": \"Full-Evening\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Fri\",\n",
      "              \"shift\": \"Full-Evening\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Sat\",\n",
      "              \"shift\": \"Full-Evening\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Sun\",\n",
      "              \"shift\": \"Full-Evening\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"id\": \"N003\",\n",
      "          \"shifts\": [\n",
      "            {\n",
      "              \"day\": \"Mon\",\n",
      "              \"shift\": \"Full-Night\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Tue\",\n",
      "              \"shift\": \"Full-Night\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Wed\",\n",
      "              \"shift\": \"Full-Night\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Thu\",\n",
      "              \"shift\": \"Full-Night\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Fri\",\n",
      "              \"shift\": \"Full-Night\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Sat\",\n",
      "              \"shift\": \"Full-Night\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Sun\",\n",
      "              \"shift\": \"Full-Night\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"id\": \"N004\",\n",
      "          \"shifts\": [\n",
      "            {\n",
      "              \"day\": \"Mon\",\n",
      "              \"shift\": \"Half-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Tue\",\n",
      "              \"shift\": \"Half-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Wed\",\n",
      "              \"shift\": \"Half-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Thu\",\n",
      "              \"shift\": \"Half-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Fri\",\n",
      "              \"shift\": \"Half-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Sat\",\n",
      "              \"shift\": \"Half-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Sun\",\n",
      "              \"shift\": \"Half-Morning\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"id\": \"N005\",\n",
      "          \"shifts\": [\n",
      "            {\n",
      "              \"day\": \"Mon\",\n",
      "              \"shift\": \"Full-Evening\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Tue\",\n",
      "              \"shift\": \"Full-Evening\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Wed\",\n",
      "              \"shift\": \"Full-Evening\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Thu\",\n",
      "              \"shift\": \"Full-Evening\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Fri\",\n",
      "              \"shift\": \"Full-Evening\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Sat\",\n",
      "              \"shift\": \"Full-Evening\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Sun\",\n",
      "              \"shift\": \"Full-Evening\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"id\": \"N006\",\n",
      "          \"shifts\": [\n",
      "            {\n",
      "              \"day\": \"Mon\",\n",
      "              \"shift\": \"Full-Night\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Tue\",\n",
      "              \"shift\": \"Full-Night\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Wed\",\n",
      "              \"shift\": \"Full-Night\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Thu\",\n",
      "              \"shift\": \"Full-Night\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Fri\",\n",
      "              \"shift\": \"Full-Night\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Sat\",\n",
      "              \"shift\": \"Full-Night\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Sun\",\n",
      "              \"shift\": \"Full-Night\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"id\": \"N007\",\n",
      "          \"shifts\": [\n",
      "            {\n",
      "              \"day\": \"Mon\",\n",
      "              \"shift\": \"Full-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Tue\",\n",
      "              \"shift\": \"Full-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Wed\",\n",
      "              \"shift\": \"Full-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Thu\",\n",
      "              \"shift\": \"Full-Morning\"\n",
      "            },\n",
      "            {\n",
      "              \"day\": \"Fri\",\n",
      "              \"shift\":\n",
      "Could not parse JSON from model output. Saving raw and skipping this episode.\n"
     ]
    }
   ],
   "source": [
    "# rl_bedrock_roster_strict.py\n",
    "import boto3\n",
    "import json\n",
    "import tarfile\n",
    "import tempfile\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import io\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from botocore.config import Config\n",
    "\n",
    "# -----------------------------\n",
    "# AWS clients & config\n",
    "# -----------------------------\n",
    "config = Config(read_timeout=120, connect_timeout=30)  # increase timeouts\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\", config=config)\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "BEDROCK_MODEL_ID = \"amazon.titan-text-premier-v1:0\"\n",
    "S3_BUCKET = \"hospital-roster-data\"\n",
    "\n",
    "# ORIGINAL model path (used for loading initial model)\n",
    "ORIG_MODEL_S3_KEY = \"training/xgboost/output/sagemaker-xgboost-2025-09-20-01-07-22-211/output/model.tar.gz\"\n",
    "\n",
    "# NEW canonical save path (store updated models here)\n",
    "NEW_MODEL_S3_KEY = \"training/xgboost/output/model.tar.gz\"\n",
    "\n",
    "# backup prefix (timestamped backups will go under this prefix)\n",
    "MODEL_BACKUP_PREFIX = \"training/xgboost/backup/\"\n",
    "\n",
    "# where to store episode rosters\n",
    "EPISODE_ROSTER_PREFIX = \"roster_history/rl_episode_rosters/\"\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: load JSON from S3\n",
    "# -----------------------------\n",
    "def load_json_from_s3(bucket, key):\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    return json.loads(obj[\"Body\"].read().decode(\"utf-8\"))\n",
    "\n",
    "# -----------------------------\n",
    "# Load S3 data (URIs as requested)\n",
    "# -----------------------------\n",
    "nurses = load_json_from_s3(S3_BUCKET, \"raw_data/nurse_data/nurse.json\")\n",
    "rules = load_json_from_s3(S3_BUCKET, \"raw_data/rules.json\")\n",
    "demand = load_json_from_s3(S3_BUCKET, \"raw_data/demand_data/demand.json\")\n",
    "shift_def = load_json_from_s3(S3_BUCKET, \"raw_data/shift.json\")\n",
    "example_roster = load_json_from_s3(S3_BUCKET, \"roster_history/roster_15092025.json\")\n",
    "\n",
    "print(\"Loaded S3 data: nurses, rules, demand, shift_def, example_roster\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load XGBoost model from original S3 URI (if available)\n",
    "# -----------------------------\n",
    "def load_model_tar_from_s3(bucket, key):\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    return io.BytesIO(obj[\"Body\"].read())\n",
    "\n",
    "def load_xgb_model_from_tarbytes(tar_bytes_io):\n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            tar_path = os.path.join(tmpdir, \"model.tar.gz\")\n",
    "            with open(tar_path, \"wb\") as f:\n",
    "                f.write(tar_bytes_io.read())\n",
    "\n",
    "            with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "                tar.extractall(path=tmpdir)\n",
    "\n",
    "            for fname in os.listdir(tmpdir):\n",
    "                cand = os.path.join(tmpdir, fname)\n",
    "                if fname == \"xgboost-model\" or fname.endswith((\".model\", \".bin\", \".json\")):\n",
    "                    booster = xgb.Booster()\n",
    "                    try:\n",
    "                        booster.load_model(cand)\n",
    "                        print(\"Loaded XGBoost booster from\", cand)\n",
    "                        return booster\n",
    "                    except Exception as e:\n",
    "                        # Try other files if one fails\n",
    "                        print(\"Failed to load candidate model file:\", cand, e)\n",
    "                        continue\n",
    "    except Exception as e:\n",
    "        print(\"Error loading model tar:\", e)\n",
    "    return None\n",
    "\n",
    "xgb_model = None\n",
    "try:\n",
    "    tar_io = load_model_tar_from_s3(S3_BUCKET, ORIG_MODEL_S3_KEY)\n",
    "    xgb_model = load_xgb_model_from_tarbytes(tar_io)\n",
    "except Exception as e:\n",
    "    print(\"Could not fetch/load initial XGBoost model:\", e)\n",
    "if xgb_model is None:\n",
    "    print(\"Proceeding with fallback scoring (no booster loaded).\")\n",
    "\n",
    "# -----------------------------\n",
    "# Bedrock call with backoff (no prompt changes)\n",
    "# -----------------------------\n",
    "def query_bedrock(prompt_text, model_id=BEDROCK_MODEL_ID, retries=6):\n",
    "    request_body = {\n",
    "        \"inputText\": prompt_text,\n",
    "        \"textGenerationConfig\": {\n",
    "            \"maxTokenCount\": 3072,\n",
    "            \"temperature\": 0.7,\n",
    "            \"topP\": 0.9,\n",
    "        }\n",
    "    }\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            resp = bedrock_client.invoke_model(\n",
    "                modelId=model_id,\n",
    "                contentType=\"application/json\",\n",
    "                accept=\"application/json\",\n",
    "                body=json.dumps(request_body)\n",
    "            )\n",
    "            result_json = json.loads(resp[\"body\"].read())\n",
    "            return result_json.get(\"results\", [{}])[0].get(\"outputText\", \"\")\n",
    "        except bedrock_client.exceptions.ThrottlingException:\n",
    "            wait = (2 ** attempt) + random.random()\n",
    "            print(f\"Throttled; backing off {wait:.2f}s\")\n",
    "            time.sleep(wait)\n",
    "        except Exception as e:\n",
    "            print(\"Bedrock invoke error:\", e)\n",
    "            break\n",
    "    return \"\"\n",
    "\n",
    "# -----------------------------\n",
    "# KEEP THE PROMPT EXACTLY AS BEFORE\n",
    "# -----------------------------\n",
    "def build_roster_prompt(instruction, nurses, rules, demand, shift_def, example_roster):\n",
    "    return f\"\"\"\n",
    "System Instructions:\n",
    "You are a nurse roster generator. Output valid JSON roster ONLY. Do not include code fences, explanations, or extra text at the beginning or end of the output. Do not put ```json at the start and end. Immediately start and end with open and close curly braces.\n",
    "Follow all HARD constraints strictly; respect SOFT preferences if possible.\n",
    "\n",
    "Constraints:\n",
    "- Daily max hours: {rules['constraints']['daily_hours_cap']}\n",
    "- Weekly max hours: {rules['constraints']['weekly_hours_cap']}\n",
    "- Rest between shifts: {rules['constraints']['rest_time_hours']}h\n",
    "- Weekly rest days: {rules['constraints']['weekly_rest_days']}\n",
    "- Max assignments per slot: {rules['constraints']['max_assignments_per_slot']['enabled']}\n",
    "- Department balance: {rules['constraints']['department_balance']['enabled']}\n",
    "- Core skill requirement: {rules['constraints']['core_skill_requirement']['enabled']}\n",
    "- Skill mix requirement: {rules['constraints']['skill_mix_requirement']['enabled']}\n",
    "- Unavailability: {rules['unavailability']['rule']}\n",
    "\n",
    "Soft preferences: {rules['preferences']['objective']}\n",
    "\n",
    "Example roster JSON format:\n",
    "{json.dumps(example_roster, indent=2)}\n",
    "\n",
    "Nurse Databse:\n",
    "{json.dumps(nurses, indent=2)}\n",
    "\n",
    "Shift demand:\n",
    "{json.dumps(demand, indent=2)}\n",
    "\n",
    "Shift definitions:\n",
    "{json.dumps(shift_def, indent=2)}\n",
    "\n",
    "Task:\n",
    "{instruction}\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# Strict hierarchical roster schema validator\n",
    "# -----------------------------\n",
    "def is_valid_hierarchical_roster(obj):\n",
    "    \"\"\"\n",
    "    Validate strict format:\n",
    "    {\n",
    "      \"departments\": [\n",
    "        {\n",
    "          \"name\": \"General\",\n",
    "          \"nurses\": [\n",
    "            {\n",
    "              \"id\": \"N034\",\n",
    "              \"shifts\": [\n",
    "                {\"day\":\"Mon\", \"shift\":\"Full-Morning\"},\n",
    "                ...\n",
    "              ]\n",
    "            },...\n",
    "          ]\n",
    "        },...\n",
    "      ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    if not isinstance(obj, dict):\n",
    "        return False\n",
    "    deps = obj.get(\"departments\")\n",
    "    if not isinstance(deps, list) or len(deps) == 0:\n",
    "        return False\n",
    "    for d in deps:\n",
    "        if not isinstance(d, dict) or \"name\" not in d or \"nurses\" not in d:\n",
    "            return False\n",
    "        if not isinstance(d[\"nurses\"], list):\n",
    "            return False\n",
    "        for n in d[\"nurses\"]:\n",
    "            if not isinstance(n, dict) or \"id\" not in n or \"shifts\" not in n:\n",
    "                return False\n",
    "            if not isinstance(n[\"shifts\"], list):\n",
    "                return False\n",
    "            for s in n[\"shifts\"]:\n",
    "                if not isinstance(s, dict) or \"day\" not in s or \"shift\" not in s:\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "# -----------------------------\n",
    "# Flatten hierarchical roster to flat assignments for training/eval\n",
    "# -----------------------------\n",
    "def flatten_hierarchical_roster(h):\n",
    "    flat = []\n",
    "    if not isinstance(h, dict):\n",
    "        return flat\n",
    "    for d in h.get(\"departments\", []):\n",
    "        dept_name = d.get(\"name\")\n",
    "        for nurse in d.get(\"nurses\", []):\n",
    "            nid = nurse.get(\"id\")\n",
    "            for s in nurse.get(\"shifts\", []):\n",
    "                day = s.get(\"day\")\n",
    "                shiftname = s.get(\"shift\")\n",
    "                flat.append({\"nurse_id\": nid, \"department\": dept_name, \"day\": day, \"shift\": shiftname})\n",
    "    return flat\n",
    "\n",
    "# -----------------------------\n",
    "# Coerce possible flat roster to hierarchical (if model returned flat list)\n",
    "# -----------------------------\n",
    "def coerce_flat_to_hierarchical(flat_list):\n",
    "    \"\"\"\n",
    "    Accepts a list of dicts like:\n",
    "      [{\"nurse_id\": \"...\", \"department\": \"...\", \"day\": \"...\", \"shift\": \"...\"}, ...]\n",
    "    Returns hierarchical roster in strict format.\n",
    "    \"\"\"\n",
    "    if not isinstance(flat_list, list):\n",
    "        return None\n",
    "    # group by department then by nurse\n",
    "    dept_map = {}\n",
    "    for a in flat_list:\n",
    "        if not isinstance(a, dict):\n",
    "            continue\n",
    "        nid = a.get(\"nurse_id\") or a.get(\"id\") or a.get(\"nurse\")\n",
    "        dept = a.get(\"department\") or a.get(\"dept\") or a.get(\"department_name\")\n",
    "        day = a.get(\"day\") or a.get(\"date\")\n",
    "        shiftname = a.get(\"shift\") or a.get(\"time\")\n",
    "        if not (nid and dept and day and shiftname):\n",
    "            # skip incomplete entries\n",
    "            continue\n",
    "        dept_map.setdefault(dept, {}).setdefault(nid, []).append({\"day\": day, \"shift\": shiftname})\n",
    "\n",
    "    departments = []\n",
    "    for dept_name, nurses_map in dept_map.items():\n",
    "        nurses_list = []\n",
    "        for nid, shifts in nurses_map.items():\n",
    "            nurses_list.append({\"id\": nid, \"shifts\": shifts})\n",
    "        departments.append({\"name\": dept_name, \"nurses\": nurses_list})\n",
    "\n",
    "    return {\"departments\": departments}\n",
    "\n",
    "# -----------------------------\n",
    "# Safe JSON extraction from model output (best-effort)\n",
    "# -----------------------------\n",
    "def safe_extract_json(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    # --- Strip markdown code fences like ```json ... ``` ---\n",
    "    # remove leading/trailing fences\n",
    "    text = re.sub(r\"```(?:json)?\", \"\", text, flags=re.IGNORECASE).strip(\"` \\n\")\n",
    "    \n",
    "    # --- Try direct parse ---\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # --- Try to extract first JSON object or array ---\n",
    "    m = re.search(r\"(\\{.*\\}|\\[.*\\])\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        return None\n",
    "    candidate = m.group(0)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(candidate)\n",
    "    except Exception:\n",
    "        # --- Try cleaning trailing commas ---\n",
    "        candidate2 = re.sub(r\",\\s*(\\]|\\})\", r\"\\1\", candidate)\n",
    "        try:\n",
    "            return json.loads(candidate2)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "# -----------------------------\n",
    "# Build features for one assignment (must match training order if you want to use xgb)\n",
    "# -----------------------------\n",
    "def build_feature_list(nurse_obj, dept, day, shiftname):\n",
    "    seniority_map = {\"Junior\": 0, \"Mid\": 1, \"Senior\": 2}\n",
    "    cand_experience = nurse_obj.get(\"experience_years\", nurse_obj.get(\"experience\", 0))\n",
    "    cand_hours_contract = nurse_obj.get(\"contracted_hours\", nurse_obj.get(\"hours_contract\", 0))\n",
    "    cand_seniority_num = seniority_map.get(nurse_obj.get(\"seniority_level\", nurse_obj.get(\"seniority\", \"Junior\")), 0)\n",
    "\n",
    "    prefs = nurse_obj.get(\"preferences\", []) or nurse_obj.get(\"pref\", []) or []\n",
    "    pref_morning = 1 if any(\"morning\" in p.lower() for p in prefs) else 0\n",
    "    pref_evening = 1 if any(\"evening\" in p.lower() for p in prefs) else 0\n",
    "    pref_night = 1 if any(\"night\" in p.lower() for p in prefs) else 0\n",
    "\n",
    "    skills = nurse_obj.get(\"skills\", []) or []\n",
    "    skill_ER = 1 if \"ER\" in skills else 0\n",
    "    skill_General = 1 if \"General\" in skills else 0\n",
    "    skill_ICU = 1 if \"ICU\" in skills else 0\n",
    "    skill_OT = 1 if \"OT\" in skills else 0\n",
    "    skill_Pediatrics = 1 if \"Pediatrics\" in skills else 0\n",
    "\n",
    "    hours_in_week = nurse_obj.get(\"hours_in_week\", 0)\n",
    "    would_violate_45 = 0\n",
    "    would_violate_8_per_day = 0\n",
    "    has_rest_day = 1 if any(\"rest\" in t.lower() for t in nurse_obj.get(\"union_terms\", [])) else 0\n",
    "\n",
    "    return [\n",
    "        float(cand_experience),\n",
    "        float(cand_hours_contract),\n",
    "        float(cand_seniority_num),\n",
    "        float(pref_morning),\n",
    "        float(pref_evening),\n",
    "        float(pref_night),\n",
    "        float(skill_ER),\n",
    "        float(skill_General),\n",
    "        float(skill_ICU),\n",
    "        float(skill_OT),\n",
    "        float(skill_Pediatrics),\n",
    "        float(hours_in_week),\n",
    "        float(would_violate_45),\n",
    "        float(would_violate_8_per_day),\n",
    "        float(has_rest_day),\n",
    "    ]\n",
    "\n",
    "# -----------------------------\n",
    "# Compatibility scoring (uses xgb if available otherwise fallback)\n",
    "# -----------------------------\n",
    "def compute_compatibility_scores(nurses, demand, xgb_model=None):\n",
    "    scores = {}\n",
    "    for nurse in nurses:\n",
    "        nid = nurse.get(\"nurse_id\") or nurse.get(\"id\") or nurse.get(\"name\")\n",
    "        for dept_name, dept_data in demand.items():\n",
    "            for day_name, shifts in dept_data.items():\n",
    "                for shift_name in shifts:\n",
    "                    feat = build_feature_list(nurse, dept_name, day_name, shift_name)\n",
    "                    if xgb_model:\n",
    "                        try:\n",
    "                            arr = np.array(feat, dtype=np.float32).reshape(1, -1)\n",
    "                            dmat = xgb.DMatrix(arr)\n",
    "                            pred = float(xgb_model.predict(dmat)[0])\n",
    "                            score = pred\n",
    "                        except Exception:\n",
    "                            score = 0.5\n",
    "                    else:\n",
    "                        score = 0.5\n",
    "                    scores[(nid, dept_name, day_name, shift_name)] = score\n",
    "    return scores\n",
    "\n",
    "compatibility_scores = compute_compatibility_scores(nurses, demand, xgb_model)\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluate a flat roster (list of assignments)\n",
    "# -----------------------------\n",
    "def evaluate_flat_roster(flat_assignments, compatibility_scores):\n",
    "    reward = 0.0\n",
    "    nurse_hours = {}\n",
    "\n",
    "    for a in flat_assignments:\n",
    "        nid = a.get(\"nurse_id\")\n",
    "        dept = a.get(\"department\")\n",
    "        day = a.get(\"day\")\n",
    "        shiftname = a.get(\"shift\")\n",
    "        if not (nid and dept and day and shiftname):\n",
    "            continue\n",
    "        key = (nid, dept, day, shiftname)\n",
    "        reward += compatibility_scores.get(key, 0.5)\n",
    "        nurse_hours[nid] = nurse_hours.get(nid, 0) + 8\n",
    "\n",
    "    penalty = sum((hrs - 45) * 0.1 for hrs in nurse_hours.values() if hrs > 45)\n",
    "    return reward - penalty\n",
    "\n",
    "# -----------------------------\n",
    "# Retrain XGBoost on episode samples and upload with backup\n",
    "# -----------------------------\n",
    "def retrain_and_upload_xgb(samples_X, samples_y, s3_bucket, save_key=NEW_MODEL_S3_KEY, backup_prefix=MODEL_BACKUP_PREFIX, num_rounds=25):\n",
    "    if len(samples_X) == 0:\n",
    "        print(\"No samples to train on; skipping retrain/upload.\")\n",
    "        return None\n",
    "    X = np.array(samples_X, dtype=np.float32)\n",
    "    y = np.array(samples_y, dtype=np.float32)\n",
    "    dtrain = xgb.DMatrix(X, label=y)\n",
    "    params = {\"objective\":\"reg:squarederror\", \"max_depth\":4, \"eta\":0.1, \"verbosity\":0}\n",
    "    booster = xgb.train(params, dtrain, num_boost_round=num_rounds)\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        model_path = os.path.join(tmpdir, \"xgboost-model\")\n",
    "        booster.save_model(model_path)\n",
    "\n",
    "        tar_path = os.path.join(tmpdir, \"model.tar.gz\")\n",
    "        with tarfile.open(tar_path, \"w:gz\") as tar:\n",
    "            tar.add(model_path, arcname=\"xgboost-model\")\n",
    "\n",
    "        # backup previous model (if exists) to backup_prefix + timestamp\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        backup_key = f\"{backup_prefix}{timestamp}/model.tar.gz\"\n",
    "\n",
    "        try:\n",
    "            # only attempt to copy if original/new key exists (head_object)\n",
    "            s3_client.head_object(Bucket=s3_bucket, Key=save_key)\n",
    "            # if exists, copy current save_key to backup location\n",
    "            s3_client.copy_object(Bucket=s3_bucket, CopySource={\"Bucket\": s3_bucket, \"Key\": save_key}, Key=backup_key)\n",
    "            print(\"Backed up previous model to\", backup_key)\n",
    "        except s3_client.exceptions.ClientError:\n",
    "            # not found or no permission - continue\n",
    "            print(\"No existing saved model to backup (ok).\")\n",
    "\n",
    "        # Upload new model to NEW_MODEL_S3_KEY (in training/xgboost/)\n",
    "        s3_client.upload_file(tar_path, s3_bucket, save_key)\n",
    "        print(\"Uploaded new model to\", save_key)\n",
    "\n",
    "    return booster\n",
    "\n",
    "# -----------------------------\n",
    "# Save roster to S3 (episode)\n",
    "# -----------------------------\n",
    "def save_roster_to_s3(roster_obj, ep_idx):\n",
    "    ts = int(time.time())\n",
    "    key = f\"{EPISODE_ROSTER_PREFIX}roster_ep_{ts}_{ep_idx}.json\"\n",
    "    body = json.dumps(roster_obj, indent=2)\n",
    "    s3_client.put_object(Bucket=S3_BUCKET, Key=key, Body=body.encode(\"utf-8\"))\n",
    "    print(\"Saved roster to s3://{}/{}\".format(S3_BUCKET, key))\n",
    "    return key\n",
    "\n",
    "# -----------------------------\n",
    "# Full RL episode loop (minimal policy; focus on generation+validate+retrain+upload)\n",
    "# -----------------------------\n",
    "def run_episodes(num_episodes=1):\n",
    "    global xgb_model, compatibility_scores\n",
    "    for ep in range(num_episodes):\n",
    "        print(\"\\n=== Episode\", ep+1, \"===\")\n",
    "        prompt = build_roster_prompt(\n",
    "            instruction=\"Generate a JSON roster for the week. Make sure to refer to the example roster to get the structured JSON format. Only output the JSON roster! Do not include code fences, explanations, or extra text at the beginning or end of the output. Do not put ```json at the start and end. Immediately start and end with open and close curly braces\",\n",
    "            nurses=nurses,\n",
    "            rules=rules,\n",
    "            demand=demand,\n",
    "            shift_def=shift_def,\n",
    "            example_roster=example_roster\n",
    "        )\n",
    "\n",
    "        out = query_bedrock(prompt)\n",
    "        print(\"Raw model output (first 5000 chars):\\n\", out[:5000])\n",
    "\n",
    "        # try to extract JSON\n",
    "        parsed = safe_extract_json(out)\n",
    "        roster_hier = None\n",
    "        if parsed is None:\n",
    "            print(\"Could not parse JSON from model output. Saving raw and skipping this episode.\")\n",
    "            s3_client.put_object(Bucket=S3_BUCKET, Key=f\"{EPISODE_ROSTER_PREFIX}raw_ep_{int(time.time())}_{ep}.json\", Body=out.encode(\"utf-8\"))\n",
    "            continue\n",
    "\n",
    "        # If parsed is already hierarchical, validate\n",
    "        if is_valid_hierarchical_roster(parsed):\n",
    "            roster_hier = parsed\n",
    "        else:\n",
    "            # If parsed is a dict with departments key but slightly malformed, try best-effort normalize:\n",
    "            if isinstance(parsed, dict) and \"departments\" in parsed:\n",
    "                # attempt flatten/repair then validate\n",
    "                flat_try = flatten_hierarchical_roster(parsed)\n",
    "                if flat_try:\n",
    "                    coerced = coerce_flat_to_hierarchical(flat_try)\n",
    "                    if coerced and is_valid_hierarchical_roster(coerced):\n",
    "                        roster_hier = coerced\n",
    "            # If parsed is a flat list, try coercion to hierarchical\n",
    "            if roster_hier is None and isinstance(parsed, list):\n",
    "                coerced = coerce_flat_to_hierarchical(parsed)\n",
    "                if coerced and is_valid_hierarchical_roster(coerced):\n",
    "                    roster_hier = coerced\n",
    "\n",
    "        if roster_hier is None:\n",
    "            # Not valid / not fixable\n",
    "            print(\"Model output is not in the strict hierarchical format and could not be coerced. Saving raw for inspection.\")\n",
    "            s3_client.put_object(Bucket=S3_BUCKET, Key=f\"{EPISODE_ROSTER_PREFIX}invalid_ep_{int(time.time())}_{ep}.json\", Body=json.dumps(parsed, indent=2).encode(\"utf-8\"))\n",
    "            continue\n",
    "\n",
    "        # roster_hier is validated strict format. Save it:\n",
    "        save_roster_to_s3(roster_hier, ep)\n",
    "\n",
    "        # Flatten and evaluate\n",
    "        flat_assignments = flatten_hierarchical_roster(roster_hier)\n",
    "        ep_reward = evaluate_flat_roster(flat_assignments, compatibility_scores)\n",
    "        print(\"Episode reward:\", ep_reward)\n",
    "\n",
    "        # Build training samples: each assignment -> features; label = ep_reward / num_assignments\n",
    "        samples_X = []\n",
    "        samples_y = []\n",
    "        per_label = float(ep_reward) / max(1, len(flat_assignments))\n",
    "        for a in flat_assignments:\n",
    "            nid = a.get(\"nurse_id\")\n",
    "            # find nurse object\n",
    "            nurse_obj = next((n for n in nurses if n.get(\"nurse_id\") == nid or n.get(\"id\") == nid or n.get(\"name\") == nid), None)\n",
    "            if nurse_obj is None:\n",
    "                # skip unknown nurse ids\n",
    "                continue\n",
    "            feat = build_feature_list(nurse_obj, a.get(\"department\"), a.get(\"day\"), a.get(\"shift\"))\n",
    "            samples_X.append(feat)\n",
    "            samples_y.append(per_label)\n",
    "\n",
    "        if len(samples_X) == 0:\n",
    "            print(\"No valid samples to retrain on this episode.\")\n",
    "            continue\n",
    "\n",
    "        # Retrain small xgboost on these samples and upload with backup\n",
    "        new_booster = retrain_and_upload_xgb(samples_X, samples_y, S3_BUCKET, save_key=NEW_MODEL_S3_KEY, backup_prefix=MODEL_BACKUP_PREFIX, num_rounds=20)\n",
    "        if new_booster:\n",
    "            xgb_model = new_booster\n",
    "            # recompute compatibility scores using updated model\n",
    "            compatibility_scores = compute_compatibility_scores(nurses, demand, xgb_model)\n",
    "            print(\"Updated compatibility scores from retrained model.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Run the loop (change episodes as needed)\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_episodes(num_episodes=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e88b6f9-13fb-4572-aa74-bce5bad92500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
